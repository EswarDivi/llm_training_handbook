# ðŸ“– The Large Language Model Training Handbook

An open collection of methodologies to help with successful training of large language models.

This is technical material suitable for LLM training engineers and operators. That is the content here contains lots of scripts and copy-n-paste commands to enable you to quickly solve your problems.

If you are not interested in technical details but want more of a detailed overview and concepts please refer to the sister [The Large Language Model Training Playbook](https://github.com/huggingface/large_language_model_training_playbook) instead.

The list of topics will expand over time.

## [Model parallelism](./parallelism)

## [Tensor precision](./dtype)

## [Selecting training hyper-parameters and model initializations](./hparams)

## [Maximizing throughput](./throughput)

## [Instabilities](./instabilities)

## [Debugging software and hardware failures](./debug/)

## [Resources](./resources/)
